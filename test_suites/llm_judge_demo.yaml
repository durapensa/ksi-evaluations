name: llm_judge_demo
version: 1.0.0
description: Demonstration of LLM-as-Judge integration with traditional evaluators
author: ksi-system

tests:
  # Test combining pipeline evaluator with LLM judge
  - name: format_with_judge
    prompt: "What is the capital of France? Format your answer as: The capital is [CITY]."
    evaluators:
      # Traditional pipeline evaluator
      - type: pipeline
        steps:
          - type: extract
            pattern: "The capital is \\[([^\\]]+)\\]"
            group: 1
            as: city
          - type: match
            input: city
            expected: "paris"
            method: exact
        weight: 0.5
      
      # LLM judge evaluator
      - type: llm_judge
        criteria:
          - name: format_compliance
            description: "Response follows the exact format: The capital is [CITY] with brackets"
            weight: 1.0
            scale_min: 1
            scale_max: 5
            examples:
              - score: 5
                description: "Perfect format with brackets: The capital is [Paris]"
              - score: 1
                description: "Missing brackets: The capital is Paris"
          
          - name: factual_accuracy
            description: "The city mentioned is factually correct"
            weight: 0.8
            scale_min: 1
            scale_max: 5
        
        judge_model: claude-cli/sonnet
        weight: 0.5
    
    success_threshold: 0.8
    tags: [llm_judge, format_validation]
    expected_behaviors: [format_compliance, factual_accuracy]

  # Test LLM judge for quality assessment
  - name: explanation_quality_judge
    prompt: "Explain in 2-3 sentences why water expands when it freezes."
    evaluators:
      # Basic checks
      - type: sentence_count
        min: 2
        max: 4
        weight: 0.2
      
      # LLM judge for quality
      - type: llm_judge
        criteria:
          - name: scientific_accuracy
            description: "Explanation is scientifically correct and mentions molecular structure"
            weight: 1.0
            scale_min: 1
            scale_max: 5
          
          - name: clarity
            description: "Explanation is clear and understandable to a general audience"
            weight: 0.8
            scale_min: 1 
            scale_max: 5
            
          - name: completeness
            description: "Covers the key concept of hydrogen bonding and crystal structure"
            weight: 0.9
            scale_min: 1
            scale_max: 5
        
        scoring_guidelines: |
          Award points based on:
          - Mentioning hydrogen bonds or molecular structure (required for score > 3)
          - Explaining the hexagonal/crystalline arrangement
          - Clarity of explanation
          - Avoiding unnecessary jargon
        
        weight: 0.8
    
    success_threshold: 0.7
    tags: [llm_judge, quality_assessment]
    expected_behaviors: [scientific_explanation, clarity]

  # Test pairwise comparison capability
  - name: creative_writing_judge
    prompt: "Write a one-sentence story about a robot learning to paint."
    evaluators:
      - type: contains_any
        patterns: ["robot", "paint", "learn"]
        weight: 0.2
      
      - type: llm_judge
        criteria:
          - name: creativity
            description: "Story shows originality and imagination"
            weight: 1.0
            scale_min: 1
            scale_max: 5
          
          - name: narrative_quality
            description: "Story has a clear narrative arc despite being one sentence"
            weight: 0.8
            scale_min: 1
            scale_max: 5
          
          - name: emotional_resonance
            description: "Story evokes emotion or connection with the robot character"
            weight: 0.7
            scale_min: 1
            scale_max: 5
        
        weight: 0.8
    
    success_threshold: 0.6
    tags: [llm_judge, creative_evaluation]
    expected_behaviors: [creativity, narrative, emotion]

contamination_patterns:
  - pattern: regex
    value: "I (cannot|can't|don't|won't)"
    severity: high
  - pattern: contains
    value: "As an AI"
    severity: medium